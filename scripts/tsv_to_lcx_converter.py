#!/usr/bin/env python3
"""
TSV to LCX Converter
–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä TSV –¥–∞–Ω–Ω—ã—Ö BrickLink –≤ LCX-Tabular —Ñ–æ—Ä–º–∞—Ç —Å–æ–≥–ª–∞—Å–Ω–æ SPEC-PART-COLOR-MAP_v2.md
"""

import csv
import json
import gzip
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
import argparse
import sys

class TSVToLCXConverter:
    def __init__(self):
        self.schema_version = 1
        self.source = "BrickLink"
        self.version = "2024.1"
        
        # –ú–∞–ø–ø–∏–Ω–≥ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
        self.header_mappings = {
            'part_color_codes': {
                'partId': ['Number', 'Item No', 'ItemNo', 'Part No', 'Part Number'],
                'colorId': ['Color ID', 'ColorID', 'Color Code'],
                'hasImg': ['Has Image', 'HasImage', 'Image', 'Img']
            },
            'colors': {
                'id': ['Color ID', 'ColorID'],
                'name': ['Color Name'],
                'rgb': ['RGB']
            },
            'parts': {
                'blId': ['Number', 'Item No', 'ItemNo'],
                'name': ['Name'],
                'catId': ['Category ID']
            }
        }
    
    def normalize_has_img(self, value: str) -> Optional[bool]:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ hasImg —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        if not value or value.strip() == '':
            return None
        
        value = value.strip().lower()
        if value in ['1', 'true', 'yes', 'y']:
            return True
        elif value in ['0', 'false', 'no', 'n']:
            return False
        else:
            return None
    
    def normalize_rgb(self, value: str) -> Optional[str]:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç RGB –∑–Ω–∞—á–µ–Ω–∏–µ –≤ HEX6 UPPERCASE –±–µ–∑ #"""
        if not value or value.strip() == '':
            return None
        
        value = value.strip().upper()
        # –£–±–∏—Ä–∞–µ–º # –µ—Å–ª–∏ –µ—Å—Ç—å
        if value.startswith('#'):
            value = value[1:]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç HEX6
        if len(value) == 6 and all(c in '0123456789ABCDEF' for c in value):
            return value
        else:
            return None
    
    def find_column_index(self, headers: List[str], possible_names: List[str]) -> Optional[int]:
        """–ù–∞—Ö–æ–¥–∏—Ç –∏–Ω–¥–µ–∫—Å –∫–æ–ª–æ–Ω–∫–∏ –ø–æ –≤–æ–∑–º–æ–∂–Ω—ã–º –Ω–∞–∑–≤–∞–Ω–∏—è–º (case-insensitive)"""
        headers_lower = [h.strip().lower() for h in headers]
        possible_names_lower = [name.strip().lower() for name in possible_names]
        
        for i, header in enumerate(headers_lower):
            if header in possible_names_lower:
                return i
        
        return None
    
    def parse_tsv_file(self, file_path: Path, data_type: str) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏—Ç TSV —Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤"""
        print(f"üìñ –ü–∞—Ä—Å–∏–Ω–≥ {file_path.name}...")
        
        if not file_path.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
        
        mapping = self.header_mappings.get(data_type, {})
        if not mapping:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö: {data_type}")
        
        rows = []
        
        with open(file_path, 'r', encoding='utf-8') as f:
            # –ß–∏—Ç–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–∫–∏
            headers = f.readline().strip().split('\t')
            
            # –ù–∞—Ö–æ–¥–∏–º –∏–Ω–¥–µ–∫—Å—ã –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
            column_indices = {}
            for field, possible_names in mapping.items():
                idx = self.find_column_index(headers, possible_names)
                if idx is not None:
                    column_indices[field] = idx
                else:
                    print(f"‚ö†Ô∏è  –ö–æ–ª–æ–Ω–∫–∞ –¥–ª—è –ø–æ–ª—è '{field}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ {file_path.name}")
                    print(f"   –û–∂–∏–¥–∞–µ–º—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è: {possible_names}")
                    print(f"   –ù–∞–π–¥–µ–Ω–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏: {headers}")
            
            # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            reader = csv.reader(f, delimiter='\t')
            for row_num, row in enumerate(reader, start=2):
                if not row or all(cell.strip() == '' for cell in row):
                    continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
                
                obj = {}
                for field, idx in column_indices.items():
                    if idx < len(row):
                        value = row[idx].strip()
                        
                        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é
                        if field == 'hasImg':
                            obj[field] = self.normalize_has_img(value)
                        elif field == 'rgb':
                            obj[field] = self.normalize_rgb(value)
                        elif field in ['id', 'colorId', 'catId']:
                            try:
                                obj[field] = int(value) if value else None
                            except ValueError:
                                obj[field] = None
                        else:
                            obj[field] = value if value else None
                    else:
                        obj[field] = None
                
                # –í–∞–ª–∏–¥–∞—Ü–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
                if data_type == 'part_color_codes':
                    if not obj.get('partId') or obj.get('colorId') is None:
                        print(f"‚ö†Ô∏è  –°—Ç—Ä–æ–∫–∞ {row_num}: –ø—Ä–æ–ø—É—â–µ–Ω–∞ (–æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è)")
                        continue
                elif data_type == 'colors':
                    if obj.get('id') is None or not obj.get('name'):
                        print(f"‚ö†Ô∏è  –°—Ç—Ä–æ–∫–∞ {row_num}: –ø—Ä–æ–ø—É—â–µ–Ω–∞ (–æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è)")
                        continue
                elif data_type == 'parts':
                    if not obj.get('blId') or not obj.get('name') or obj.get('catId') is None:
                        print(f"‚ö†Ô∏è  –°—Ç—Ä–æ–∫–∞ {row_num}: –ø—Ä–æ–ø—É—â–µ–Ω–∞ (–æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è)")
                        continue
                
                rows.append(obj)
        
        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(rows)} —Å—Ç—Ä–æ–∫ –∏–∑ {file_path.name}")
        return rows
    
    def deduplicate_part_colors(self, part_colors: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """–î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Å–≤—è–∑–µ–π part-color —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        print("üîÑ –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Å–≤—è–∑–µ–π –¥–µ—Ç–∞–ª—å-—Ü–≤–µ—Ç...")
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–ª—é—á—É (partId, colorId)
        groups = {}
        for item in part_colors:
            key = (item['partId'], item['colorId'])
            if key not in groups:
                groups[key] = []
            groups[key].append(item)
        
        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º hasImg –ø–æ –ø—Ä–∞–≤–∏–ª—É "–µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ true"
        deduplicated = []
        for key, items in groups.items():
            part_id, color_id = key
            
            # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º hasImg
            has_img_values = [item['hasImg'] for item in items if item['hasImg'] is not None]
            if has_img_values:
                has_img_agg = any(has_img_values)  # True –µ—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ true
            else:
                has_img_agg = None  # –ï—Å–ª–∏ –Ω–µ –±—ã–ª–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —è–≤–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è
            
            deduplicated.append({
                'partId': part_id,
                'colorId': color_id,
                'hasImg': has_img_agg
            })
        
        print(f"‚úÖ –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(part_colors)} ‚Üí {len(deduplicated)} —Å–≤—è–∑–µ–π")
        return deduplicated
    
    def validate_data(self, part_colors: List[Dict], colors: List[Dict], parts: List[Dict]) -> Dict[str, Any]:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞"""
        print("üîç –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö...")
        
        # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        color_ids = {color['id'] for color in colors if color.get('id') is not None}
        part_ids = {part['blId'] for part in parts if part.get('blId')}
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏
        total_links = len(part_colors)
        unique_parts = len(set(item['partId'] for item in part_colors))
        unique_colors = len(set(item['colorId'] for item in part_colors))
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Ü–≤–µ—Ç–∞
        unknown_colors = [item for item in part_colors if item['colorId'] not in color_ids]
        unknown_colors_pct = (len(unknown_colors) / total_links * 100) if total_links > 0 else 0
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –¥–µ—Ç–∞–ª–∏
        unknown_parts = [item for item in part_colors if item['partId'] not in part_ids]
        unknown_parts_pct = (len(unknown_parts) / total_links * 100) if total_links > 0 else 0
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ hasImg
        has_img_true = len([item for item in part_colors if item['hasImg'] is True])
        has_img_null = len([item for item in part_colors if item['hasImg'] is None])
        has_img_true_pct = (has_img_true / total_links * 100) if total_links > 0 else 0
        has_img_null_pct = (has_img_null / total_links * 100) if total_links > 0 else 0
        
        metrics = {
            'links_total': total_links,
            'parts_total': unique_parts,
            'colors_total': unique_colors,
            'unknown_colors_count': len(unknown_colors),
            'unknown_colors_pct': round(unknown_colors_pct, 2),
            'unknown_parts_count': len(unknown_parts),
            'unknown_parts_pct': round(unknown_parts_pct, 2),
            'has_img_true_count': has_img_true,
            'has_img_true_pct': round(has_img_true_pct, 2),
            'has_img_null_count': has_img_null,
            'has_img_null_pct': round(has_img_null_pct, 2)
        }
        
        print("üìä –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞:")
        print(f"   –°–≤—è–∑–µ–π –≤—Å–µ–≥–æ: {metrics['links_total']:,}")
        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π: {metrics['parts_total']:,}")
        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ü–≤–µ—Ç–æ–≤: {metrics['colors_total']:,}")
        print(f"   –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ü–≤–µ—Ç–æ–≤: {metrics['unknown_colors_count']:,} ({metrics['unknown_colors_pct']}%)")
        print(f"   –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π: {metrics['unknown_parts_count']:,} ({metrics['unknown_parts_pct']}%)")
        print(f"   hasImg=true: {metrics['has_img_true_count']:,} ({metrics['has_img_true_pct']}%)")
        print(f"   hasImg=null: {metrics['has_img_null_count']:,} ({metrics['has_img_null_pct']}%)")
        
        return metrics
    
    def create_lcx_structure(self, part_colors: List[Dict], colors: List[Dict], parts: List[Dict], categories: List[Dict] = None) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç LCX —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö"""
        print("üèóÔ∏è  –°–æ–∑–¥–∞–Ω–∏–µ LCX —Å—Ç—Ä—É–∫—Ç—É—Ä—ã...")
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        part_colors_sorted = sorted(part_colors, key=lambda x: (x['partId'], x['colorId']))
        colors_sorted = sorted(colors, key=lambda x: x['id'])
        parts_sorted = sorted(parts, key=lambda x: x['blId'])
        
        lcx_data = {
            'schemaVersion': self.schema_version,
            'source': self.source,
            'version': self.version,
            'tables': {
                'partColors': {
                    'cols': ['partId', 'colorId', 'hasImg'],
                    'rows': [[item['partId'], item['colorId'], item['hasImg']] for item in part_colors_sorted]
                },
                'colors': {
                    'cols': ['id', 'name', 'rgb'],
                    'rows': [[item['id'], item['name'], item['rgb']] for item in colors_sorted]
                },
                'parts': {
                    'cols': ['blId', 'name', 'catId'],
                    'rows': [[item['blId'], item['name'], item['catId']] for item in parts_sorted]
                }
            }
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
        if categories:
            categories_sorted = sorted(categories, key=lambda x: x['id'])
            lcx_data['tables']['categories'] = {
                'cols': ['id', 'name'],
                'rows': [[item['id'], item['name']] for item in categories_sorted]
            }
        
        return lcx_data
    
    def convert(self, input_dir: Path, output_file: Path, compress: bool = True) -> Dict[str, Any]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏"""
        print("üöÄ TSV to LCX Converter (SPEC v2)")
        print("=" * 50)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        required_files = {
            'part_color_codes': input_dir / 'part_color_codes.tab'
        }
        
        optional_files = {
            'colors': input_dir / 'colors.tab',
            'parts': input_dir / 'parts.tab',
            'categories': input_dir / 'categories.tab'
        }
        
        missing_required = [name for name, path in required_files.items() if not path.exists()]
        if missing_required:
            raise FileNotFoundError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã: {missing_required}")
        
        # –ü–∞—Ä—Å–∏–º –¥–∞–Ω–Ω—ã–µ
        part_colors = self.parse_tsv_file(required_files['part_color_codes'], 'part_color_codes')
        
        colors = []
        if optional_files['colors'].exists():
            colors = self.parse_tsv_file(optional_files['colors'], 'colors')
        
        parts = []
        if optional_files['parts'].exists():
            parts = self.parse_tsv_file(optional_files['parts'], 'parts')
        
        categories = []
        if optional_files['categories'].exists():
            categories = self.parse_tsv_file(optional_files['categories'], 'categories')
        
        # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è
        part_colors = self.deduplicate_part_colors(part_colors)
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        metrics = self.validate_data(part_colors, colors, parts)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ LCX —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        lcx_data = self.create_lcx_structure(part_colors, colors, parts, categories)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ {output_file}...")
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        json_str = json.dumps(lcx_data, ensure_ascii=False, separators=(',', ':'))
        
        if compress:
            with gzip.open(output_file, 'wt', encoding='utf-8') as f:
                f.write(json_str)
            print(f"‚úÖ –°–∂–∞—Ç—ã–π LCX —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
        else:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(json_str)
            print(f"‚úÖ LCX —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {output_file}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        lcx_data['metrics'] = metrics
        
        return lcx_data


def main():
    parser = argparse.ArgumentParser(description='–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä TSV –¥–∞–Ω–Ω—ã—Ö BrickLink –≤ LCX —Ñ–æ—Ä–º–∞—Ç')
    parser.add_argument('input_dir', type=Path, help='–ü–∞–ø–∫–∞ —Å TSV —Ñ–∞–π–ª–∞–º–∏ BrickLink')
    parser.add_argument('-o', '--output', type=Path, default=Path('bricklink-catalog.lcx.json.gz'), 
                       help='–í—ã—Ö–æ–¥–Ω–æ–π LCX —Ñ–∞–π–ª (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: bricklink-catalog.lcx.json.gz)')
    parser.add_argument('--no-compress', action='store_true', help='–ù–µ —Å–∂–∏–º–∞—Ç—å –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª')
    
    args = parser.parse_args()
    
    try:
        converter = TSVToLCXConverter()
        result = converter.convert(args.input_dir, args.output, not args.no_compress)
        
        print("\nüéâ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìä –ò—Ç–æ–≥–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏:")
        for key, value in result['metrics'].items():
            print(f"   {key}: {value}")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
